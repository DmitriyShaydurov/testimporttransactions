# Тестовое задание

## Установка
Выполните установку проекта Laravel как обычно.

## Схема
Создайте необходимые миграции для хранения данных.

## ImporterService
Реализуйте `ImporterService`. Вы можете вносить любые необходимые изменения.

Ваша реализация должна использовать `$mapping` для нахождения нужного значения в csv файле. Это означает, что хардкодить позиции или названия колонок запрещено.

Обратите внимание, что ваша программа должна иметь возможность импортировать больше файлы, которые не смогут уместиться в памяти.

Стоит обратить внимание на следующее:
- Каждый Merchant может иметь много Batches, а каждый Batch - много Transactions
- Уникальный ключ Merchant: `Report::MERCHANT_ID`
- Уникальный ключ Batch - это комбинация `Report::MERCHANT_ID`, `Report::BATCH_DATE` и `Report::BATCH_REF_NUM`
- У транзакций нет уникального ключа
- Приветствуются оптимизации, которые позволят сэкономить память и выполнить как можно меньше запросов к БД

## Запросы
Напишите запросы в файле `queries.sql`.

# Описание Проекта

## Обзор
Проект представляет собой систему для импорта данных из CSV-файлов в базу данных. Данные организованы в три основные сущности: `Merchant`, `Batch`, и `Transaction`. Проект оптимизирован для работы с большими файлами и минимизации использования памяти.



## ImporterService
`ImporterService` является основным компонентом, который отвечает за обработку CSV-файлов. 
он использует несколько сервисов
- **CSVReader**: Компонент для чтения CSV-файла. С использованием библиотеки `League\Csv\Reader` файл читается построчно, что позволяет работать с файлами большого размера.
- **DataProcessor**: Компонент для обработки строк CSV. Преобразует строки CSV в структурированные данные для `Merchant`, `Batch`, и `Transaction`.
- **Data Inserter (dataInserter)**: Этот компонент отвечает за вставку данных (таких как merchants, batches, и transactions) в базу данных. Он использует метод `insertData`, который берет подготовленные массивы данных и вставляет их в соответствующие таблицы БД. Эта оптимизация позволяет группировать операции вставки, что может существенно уменьшить количество запросов к БД и улучшить общую производительность импорта.
- **Выбор `BUFFER_SIZE`**: Параметр `BUFFER_SIZE` контролирует количество записей, которые будут обработаны перед вставкой данных в базу данных. Подбор оптимального значения для этого параметра может зависеть от нескольких факторов, таких как размер памяти сервера, размеры обрабатываемых файлов и специфика БД. Маленькое значение может привести к частым, но менее затратным операциям вставки, в то время как большое значение может уменьшить количество запросов к БД, но потребовать больше оперативной памяти. Тестирование с различными значениями `BUFFER_SIZE` на целевом оборудовании может помочь найти оптимальный баланс между использованием памяти и производительностью.



## Оптимизации
- **Reading File Line-by-Line**: Вместо загрузки всего файла в память, CSV-файл читается построчно с использованием `Reader::createFromPath($filename, 'r')`. Это обеспечивает возможность обработки очень больших файлов, которые могут не уместиться в памяти, так как в любой момент времени в памяти хранится только одна строка файла.
-- **Batch Processing**: Данные обрабатываются пакетами, определяемыми размером BUFFER_SIZE. Пакетная обработка экономит память и ускоряет запись в БД.
- **Passing by Reference**: В `ImporterService`, массивы `$merchants`, `$batches`, и `$transactions` передаются по ссылке (`&$merchants`, `&$batches`, `&$transactions`) в метод `processRecord`. Это позволяет методу модифицировать оригинальные массивы без создания новых копий, что экономит память и делает код более эффективным.

## Заключение
Проект представляет собой эффективную и гибкую систему для импорта данных из CSV-файлов. Он оптимизирован для работы с большими файлами и построен с учетом лучших практик программирования, что обеспечивает его надежность и легкость в обслуживании.

